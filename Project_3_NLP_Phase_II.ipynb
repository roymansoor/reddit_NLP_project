{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the data\n",
    "asklove=pd.read_csv('./raw_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, title, selftext, subreddit, created_utc, author, num_comments, score, is_self, timestamp]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asklove.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping usless columns\n",
    "asklove=asklove.drop(['Unnamed: 0','created_utc', 'author', 'num_comments', 'score','is_self','timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Missed opportunities...</td>\n",
       "      <td>I want to take a moment to talk about missed o...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You ever wish you can marry you can marry your...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You ever fall inlove with your own cousin and ...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My Love is My Own</td>\n",
       "      <td>My love is my own.\\n\\nIt is most powerful and ...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The day my stalker became the love of my life....</td>\n",
       "      <td>Things can change in an instant. In one blink ...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tinder Date to Relationship</td>\n",
       "      <td>Well..English is not my mother tongue, so you ...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Just a way of expressing what I feel since the...</td>\n",
       "      <td>4th March 2019\\nI cant describe what im feelin...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>He missed me</td>\n",
       "      <td>Even tho he didn’t say so he initiated a lot m...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>emotional problems and left Index finger pain?!</td>\n",
       "      <td>when someone you love say or did something tha...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>guuyyyssss I’m confused she talked about going...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                            Missed opportunities...   \n",
       "1  You ever wish you can marry you can marry your...   \n",
       "2  You ever fall inlove with your own cousin and ...   \n",
       "3                                  My Love is My Own   \n",
       "4  The day my stalker became the love of my life....   \n",
       "5                        Tinder Date to Relationship   \n",
       "6  Just a way of expressing what I feel since the...   \n",
       "7                                       He missed me   \n",
       "8    emotional problems and left Index finger pain?!   \n",
       "9  guuyyyssss I’m confused she talked about going...   \n",
       "\n",
       "                                            selftext subreddit  \n",
       "0  I want to take a moment to talk about missed o...      love  \n",
       "1                                          [removed]      love  \n",
       "2                                          [removed]      love  \n",
       "3  My love is my own.\\n\\nIt is most powerful and ...      love  \n",
       "4  Things can change in an instant. In one blink ...      love  \n",
       "5  Well..English is not my mother tongue, so you ...      love  \n",
       "6  4th March 2019\\nI cant describe what im feelin...      love  \n",
       "7  Even tho he didn’t say so he initiated a lot m...      love  \n",
       "8  when someone you love say or did something tha...      love  \n",
       "9                                                NaN      love  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asklove.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[removed]    985\n",
       "Name: selftext, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking [removed] in our df\n",
    "(asklove[(asklove['selftext']=='[removed]')]['selftext']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using fillna to fill non values '' and save it \n",
    "asklove.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using applymap lambda replacing [removed] with ' '\n",
    "asklove=asklove.applymap(lambda x: x.replace('[removed]', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Missed opportunities...</td>\n",
       "      <td>I want to take a moment to talk about missed o...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                           selftext  \\\n",
       "0  Missed opportunities...  I want to take a moment to talk about missed o...   \n",
       "\n",
       "  subreddit  \n",
       "0      love  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asklove.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combinging the two columns title and selftext and creatiing new column dada\n",
    "asklove['data']=asklove['title']+asklove['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping the old columns \n",
    "asklove=asklove.drop(['title', 'selftext'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>Missed opportunities...I want to take a moment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love</td>\n",
       "      <td>You ever wish you can marry you can marry your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love</td>\n",
       "      <td>You ever fall inlove with your own cousin and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love</td>\n",
       "      <td>My Love is My OwnMy love is my own.\\n\\nIt is m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>The day my stalker became the love of my life....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                               data\n",
       "0      love  Missed opportunities...I want to take a moment...\n",
       "1      love  You ever wish you can marry you can marry your...\n",
       "2      love  You ever fall inlove with your own cousin and ...\n",
       "3      love  My Love is My OwnMy love is my own.\\n\\nIt is m...\n",
       "4      love  The day my stalker became the love of my life...."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asklove.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit    0\n",
       "data         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "asklove.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4975 entries, 0 to 4974\n",
      "Data columns (total 2 columns):\n",
      "subreddit    4975 non-null object\n",
      "data         4975 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 77.8+ KB\n"
     ]
    }
   ],
   "source": [
    "asklove.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>Missed opportunities...I want to take a moment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love</td>\n",
       "      <td>You ever wish you can marry you can marry your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love</td>\n",
       "      <td>You ever fall inlove with your own cousin and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love</td>\n",
       "      <td>My Love is My OwnMy love is my own.\\n\\nIt is m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>The day my stalker became the love of my life....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                               data\n",
       "0      love  Missed opportunities...I want to take a moment...\n",
       "1      love  You ever wish you can marry you can marry your...\n",
       "2      love  You ever fall inlove with your own cousin and ...\n",
       "3      love  My Love is My OwnMy love is my own.\\n\\nIt is m...\n",
       "4      love  The day my stalker became the love of my life...."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asklove.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummifiy subreddit column to make it 0 an 1 \n",
    "column=['subreddit']\n",
    "asklove=pd.get_dummies(asklove, columns=column, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Missed opportunities...I want to take a moment...\n",
       "1    You ever wish you can marry you can marry your...\n",
       "2    You ever fall inlove with your own cousin and ...\n",
       "3    My Love is My OwnMy love is my own.\\n\\nIt is m...\n",
       "4    The day my stalker became the love of my life....\n",
       "5    Tinder Date to RelationshipWell..English is no...\n",
       "6    Just a way of expressing what I feel since the...\n",
       "7    He missed meEven tho he didn’t say so he initi...\n",
       "8    emotional problems and left Index finger pain?...\n",
       "9    guuyyyssss I’m confused she talked about going...\n",
       "Name: data, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the first 10 comments.\n",
    "asklove['data'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>subreddit_love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Missed opportunities...I want to take a moment...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You ever wish you can marry you can marry your...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You ever fall inlove with your own cousin and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My Love is My OwnMy love is my own.\\n\\nIt is m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The day my stalker became the love of my life....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  subreddit_love\n",
       "0  Missed opportunities...I want to take a moment...               1\n",
       "1  You ever wish you can marry you can marry your...               1\n",
       "2  You ever fall inlove with your own cousin and ...               1\n",
       "3  My Love is My OwnMy love is my own.\\n\\nIt is m...               1\n",
       "4  The day my stalker became the love of my life....               1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asklove.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing - Model - Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning out data the title and content to x, and the subreddit_love to y.\n",
    "X= asklove['data']\n",
    "y= asklove['subreddit_love']\n",
    "#train test split our x and y, 25%, 75% randome state 42, and stratify to yes becasue its clasification problem \n",
    "# and ensure that the train and test sets have approximately the same percentage of samples of each \n",
    "#target class as the complete set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pipleline our code looks clean and organized. \n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()), #instenciate count vectorizer  \n",
    "    ('lr', LogisticRegression()) #and logistic regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CV Logistic Regression:  0.9321897614580541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.5,\n",
       " 'cvec__max_features': 3500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#giving the preameters for count vectorizer\n",
    "pipe_params = {\n",
    "    # adjusting features to reduce variance \n",
    "    'cvec__max_features': [2000,2500, 3000,3500],\n",
    "    # trying stopwords and none\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    #ignore terms that appear in more than 2, 3,4 documents. trying to find the best fit \n",
    "    'cvec__min_df': [2,3,4],\n",
    "    #ignore terms that appear in more than 50% of the documents and so on. trying to find the best one\n",
    "    'cvec__max_df': [.5,.9 ,.95],\n",
    "    # ngram (1,1) looks only one word and 1,2 looks that word with a word before and after \n",
    "    #so we try both to get the best peramtert\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "asklove = GridSearchCV(pipe, param_grid=pipe_params, cv=3)#using Grid search fit and score our model\n",
    "asklove.fit(X_train, y_train)\n",
    "print(f' CV Logistic Regression:  {asklove.best_score_}')\n",
    "asklove.best_params_ #using best_prams getting the best premeters and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Lr Train Score :0.9839185205038864\n",
      "CV Lr Test Score  :0.9389067524115756\n"
     ]
    }
   ],
   "source": [
    "#getting the accuracy on train and test data\n",
    "print (f'CV Lr Train Score :{asklove.score(X_train, y_train)}') \n",
    "print (f'CV Lr Test Score  :{asklove.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pipeline count vectroize and naive bayes\n",
    "pipe_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),#instenciate count vectorizer \n",
    "    ('nb', MultinomialNB()),#and logistic regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Naive Bayes: 0.9112838381131064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.5,\n",
       " 'cvec__max_features': 3500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the premeters\n",
    "pipe_params_nb = {\n",
    "    # adjusting features to reduce variance \n",
    "    'cvec__max_features': [2000,2500, 3000,3500, 4000,4500],\n",
    "    # trying stopwords and none\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    #ignore terms that appear in more than 2, 3,4 documents. trying to find the best fit \n",
    "    'cvec__min_df': [1,2,3,4],\n",
    "    #ignore terms that appear in more than 20% of the documents and so on. trying to find the best one\n",
    "    'cvec__max_df': [.2,.5,.9 ,.95],\n",
    "    # ngram (1,1) looks only one word and 1,2 looks that word with a word before and after \n",
    "    #so we try both to get the best peramtert\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "asklove = GridSearchCV(pipe_nb, param_grid=pipe_params, cv=3)#using Grid search fit and score our model\n",
    "asklove.fit(X_train, y_train)\n",
    "print(f'CV Naive Bayes: {asklove.best_score_}')\n",
    "asklove.best_params_#using best_prams getting the best premeters and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV nb Train Score :0.9265612436344144\n",
      "CV nb Test Score  :0.9244372990353698\n"
     ]
    }
   ],
   "source": [
    "#priinting the scores for test and train data\n",
    "print (f'CV nb Train Score :{asklove.score(X_train, y_train)}') \n",
    "print (f'CV nb Test Score  :{asklove.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##trying to print the confusion matrix \n",
    "# from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=3500, min_df=2,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asklove.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF- Lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instenciate TFIDF for tokanizing, trying diffrent way other steps are same as abovie \n",
    "tvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pipeline putting TFIDF and logistic regression in it for the next step \n",
    "pipe_tif_lr = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9289734655588314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.5,\n",
       " 'tvec__max_features': 4000,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 2),\n",
       " 'tvec__stop_words': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipe_params_tif_lr = {\n",
    "    # trying stopwords and none\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    # ngram (1,1) looks only one word and 1,2 looks that word with a word before and after \n",
    "    #so we try both to get the best peramtert\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (2,3)],\n",
    "    #ignore terms that appear in more than 1, 2, 3,4 documents. trying to find the best fit \n",
    "    'tvec__min_df': [1,2,3,4],\n",
    "    #ignore terms that appear in more than 20% of the documents and so on. trying to find the best one\n",
    "    'tvec__max_df': [.2,.5,.9 ,.95],\n",
    "    # adjusting features to reduce variance \n",
    "    'tvec__max_features': [2000,2500, 3000,3500, 4000,4500]\n",
    "}\n",
    "asklove = GridSearchCV(pipe_tif_lr, param_grid=pipe_params_tif_lr, cv=3)\n",
    "asklove.fit(X_train, y_train)\n",
    "print(asklove.best_score_)\n",
    "asklove.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIFDF Lr Train Score :0.960332350576253\n",
      "TIFDF Lr Test Score  :0.9397106109324759\n"
     ]
    }
   ],
   "source": [
    "print (f'TIFDF Lr Train Score :{asklove.score(X_train, y_train)}') \n",
    "print (f'TIFDF Lr Test Score  :{asklove.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF- nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expermentinig TFIDF and naive bayes\n",
    "pipe_nb_tif = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB()),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9203966764942375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.5,\n",
       " 'tvec__max_features': 3500,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 2),\n",
       " 'tvec__stop_words': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params_nb_tif = {\n",
    "     # trying stopwords and none\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    # ngram (1,1) looks only one word and 1,2 looks that word with a word before and after \n",
    "    #so we try both to get the best peramtert\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (2,3)],\n",
    "    #ignore terms that appear in more than 1, 2, 3,4 documents. trying to find the best fit \n",
    "    'tvec__min_df': [1,2,3,4],\n",
    "    #ignore terms that appear in more than 20% of the documents and so on. trying to find the best one\n",
    "    'tvec__max_df': [.2,.5,.9 ,.95],\n",
    "    # adjusting features to reduce variance \n",
    "    'tvec__max_features': [2000,2500, 3000,3500, 4000,4500]\n",
    "    \n",
    "    }\n",
    "asklove = GridSearchCV(pipe_nb_tif, param_grid=pipe_params_nb_tif, cv=3)\n",
    "asklove.fit(X_train, y_train)\n",
    "print(asklove.best_score_)\n",
    "asklove.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIFDF nb Train Score :0.9407665505226481\n",
      "TIFDF nb Test Score  :0.9236334405144695\n"
     ]
    }
   ],
   "source": [
    "print (f'TIFDF nb Train Score :{asklove.score(X_train, y_train)}') \n",
    "print (f'TIFDF nb Test Score  :{asklove.score(X_test, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
